{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostgreSQL and Python\n",
    "\n",
    "In the lecture we have talked about Databases and particulartly relational databases such as [PostgreSQL](http://www.postgresql.org). The standard language to interact with relational databases is SQL, which both serves as a \n",
    "* *Data Definition Language (DDL)* - to [define](https://www.postgresql.org/docs/9.3/static/sql-createtable.html), [modify](https://www.postgresql.org/docs/9.3/static/sql-altertable.html), and [drop]((https://www.postgresql.org/docs/9.3/static/sql-droptable.html) **tables** (as the central type of objects to store data as records in such tables), their relations, [constraints](https://www.postgresql.org/docs/9.3/static/ddl-constraints.html) on the data and other objects such as views, [indexes](https://www.postgresql.org/docs/9.3/static/sql-createindex.html), [triggers](https://www.postgresql.org/docs/9.3/static/sql-createtrigger.html), etc.\n",
    "* *Data Manipultation Language (DML)* - to [insert](https://www.postgresql.org/docs/9.3/static/sql-insert.html) and [update](https://www.postgresql.org/docs/9.3/static/sql-update.html) data in tables, as well as to [query](https://www.postgresql.org/docs/9.3/static/sql-select.html) data.\n",
    " \n",
    "In order to execute some SQL commands, you can go directly to the terminal and run the SQL files in a text file (typical suffix `.sql`) using `psql`, as we have seen in the slides:\n",
    "\n",
    "      $ psql < data/entry_tutorial_example.sql\n",
    "      \n",
    "The file [data/entry_tutorial_example.sql](data/entry_tutorial_example.sql) actually creates tables named \"Produkt\" and \"Preis\" like in the entry tutorial.\n",
    "You can now continue using `psql` and execute the queries in the slides... or use SQL directly from Python3. How?\n",
    "\n",
    "## Using the psycopg2 Module\n",
    "\n",
    "In Python, there are [several modules](https://wiki.postgresql.org/wiki/Python) to connect to a [PostgreSQL](http://www.postgresql.org) server, particularly, [psycopg2](http://initd.org/psycopg/) as the most popular Python driver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First you have to define a `connection` to the database: the function `connect()` creates a new database session and returns a new `connection` instance.  The class `connection` encapsulates a database session. It allows you to e.g. create new `cursor`s using the `cursor()` method to execute database commands and queries.\n",
    "\n",
    "You can use a cursor to execute DDL+DML statements: the class `cursor` allows interaction with the database:\n",
    "* send commands to the database using methods such as `execute()` and `executemany()`,\n",
    "* retrieve data from the database by iteration or using methods such as `fetchone()`, `fetchmany()`, `fetchall()`.\n",
    "\n",
    "Note that in the end, you have to:\n",
    " * commit changes to be written into in your database persistently (if you have done updates, insertions, or deletions\n",
    " * close both the cursor and the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup table\n",
    "\n",
    "taken from \"./data/entry_tutorial_example.sql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open the connection:\n",
    "conn = psycopg2.connect(\"dbname=postgres user=postgres\") as conn:\n",
    "\n",
    "#Open a cursor to perform database operations\n",
    "cur = conn.cursor()\n",
    "\n",
    "#-- drop the table if it already exists:\n",
    "#cur.execute(\"DROP TABLE Produkt;\")\n",
    "\n",
    "#-- create the product table:\n",
    "cur.execute(\"CREATE TABLE Produkt (ProduktNr integer  PRIMARY KEY NOT NULL, Bezeichnung varchar(50), Preisgruppe char(2));\")\n",
    "#conn.commit()\n",
    "#-- insert some values:\n",
    "cur.execute(\"INSERT INTO Produkt VALUES (1, 'Notitzblock A4 kariert', 'G3');\")\n",
    "cur.execute(\"INSERT INTO Produkt VALUES (2, 'Notitzblock A5 liniert', 'G2');\")\n",
    "cur.execute(\"INSERT INTO Produkt VALUES (3, 'Notitzblock A4 liniert', 'G3');\")\n",
    "cur.execute(\"INSERT INTO Produkt VALUES (4, 'Notitzblock A6 glatt', 'G1');\")\n",
    "cur.execute(\"INSERT INTO Produkt VALUES (5, 'Kopierpapier 500 Blatt', 'G7');\")\n",
    "cur.execute(\"INSERT INTO Produkt VALUES (6, 'Notitzblock A5 glatt', 'G3');\")\n",
    "\n",
    "\n",
    "#-- drop the table if it already exists:\n",
    "#cur.execute(\"DROP TABLE Preis;\")\n",
    "\n",
    "#-- create the Preis table:\n",
    "cur.execute(\"CREATE TABLE Preis (Preisgruppe char(2) PRIMARY KEY NOT NULL, Betrag decimal);\")\n",
    "\n",
    "cur.execute(\"INSERT INTO Preis VALUES ( 'G1', 0.50 );\")\n",
    "cur.execute(\"INSERT INTO Preis VALUES ( 'G2', 1.50 );\")\n",
    "cur.execute(\"INSERT INTO Preis VALUES ( 'G3', 3.00 );\")\n",
    "cur.execute(\"INSERT INTO Preis VALUES ( 'G4', 3.25 );\")\n",
    "cur.execute(\"INSERT INTO Preis VALUES ( 'G5', 5.00 );\")\n",
    "cur.execute(\"INSERT INTO Preis VALUES ( 'G6', 5.50 );\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Open the connection:\n",
    "conn = psycopg2.connect(\"dbname=postgres user=postgres\") as conn:\n",
    "\n",
    "#Open a cursor to perform database operations\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a command: update the price of group 'G4' to 4.00 \n",
    "cur.execute(\"UPDATE Preis SET Betrag = 4.0 WHERE Preisgruppe = 'G4'\")\n",
    "\n",
    "# Pass data to fill a query placeholders and let Psycopg perform\n",
    "# the correct conversion (no more SQL injections!)\n",
    "prodnr = 7\n",
    "descr = \"Neues Produkt\"\n",
    "group = 3\n",
    "\n",
    "cur.execute(\"INSERT INTO Produkt (ProduktNr, Bezeichnung,Preisgruppe) VALUES (%s, %s, 'G%s')\",\n",
    "      (prodnr, descr, group))\n",
    "\n",
    "# Query the database and obtain data as Python (tuple) objects\n",
    "cur.execute(\"SELECT * FROM Produkt;\")\n",
    "print(cur.fetchall())\n",
    "\n",
    "# Make the changes to the database persistent\n",
    "conn.commit()\n",
    "\n",
    "# Close communication (both the cursor and the connection) with the database\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to execute the above block twice, you get an error... Why? Hint: Look at [data/entry_tutorial_example.sql](data/entry_tutorial_example.sql) to find the answer - and recall what a [PRIMARY KEY](https://www.postgresql.org/docs/9.3/static/ddl-constraints.html) in a table is! (You should remember this from BIS I, BTW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store and query json data, or a dictionatry (as json) in Postgres:\n",
    "* in order to load Json, we need the [Json](http://initd.org/psycopg/docs/extras.html#psycopg2.extras.Json) adaptor in the `psycopg2.extras` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austria\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from psycopg2.extras import Json\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=postgres user=postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"DROP TABLE jsondummytable\")\n",
    "cur.execute(\"CREATE TABLE jsondummytable (data json)\")\n",
    "\n",
    "\n",
    "filePath='./data/alice.json'\n",
    "\n",
    "with open(filePath, 'r') as f:\n",
    "    data=json.load(f)\n",
    "    cur.execute('INSERT INTO jsondummytable VALUES(%s)', [Json(data)])\n",
    "\n",
    "# A little bit more complex query on a json object, cf. \n",
    "#  https://www.postgresql.org/docs/9.3/static/functions-json.html\n",
    "# for details:\n",
    "# Get the country of the first shipping address for the record where the name is 'Alice'\n",
    "cur.execute(\"SELECT data->'shipping_addresses'->0->>'country'as name FROM jsondummytable \\\n",
    "             WHERE data->>'firstname' = 'Alice';\")\n",
    "# BTW: note here also you can do a line break within a string in the query with a \\\n",
    "print(cur.fetchone()[0])\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex use case around our City Data use case\n",
    "\n",
    "Now that we know how to establish some basic interaction with a database, let's try to solve the following task.\n",
    "We learnt how to do filtering and merging of data with Python in [Unit3](http://).\n",
    "\n",
    "This can be actually done within a database as well:\n",
    "* Store the the EUROSTAT populations table, the iso country codes table, \n",
    "  and the indicator tables in the database in the database.\n",
    "* Formulate an SQL query that gets me the 2014 average populations for cities per country, ordered by the country name.\n",
    "\n",
    "**Discuss**: What's better? Doing it directly in Python, or doing it in SQL? Discuss pros and cons!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st alternative to look into: store dictionaries as JSON in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "cityCodeFile=\"./data/cities.csv\"\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=postgres user=postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#Building the cityCode to Label map\n",
    "cityCodeMap={}\n",
    "with open(cityCodeFile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "    for i,row in enumerate(csvfile):\n",
    "        cityCodeMap[row[3]]= row[1]\n",
    "#cityCodeMap\n",
    "\n",
    "# cur.execute(\"DROP TABLE cityCodeMap\")\n",
    "cur.execute(\"CREATE TABLE cityCodeMap (data json)\")\n",
    "cur.execute('INSERT INTO cityCodeMap VALUES(%s)', [Json(cityCodeMap)])\n",
    "\n",
    "cur.execute(\"SELECT data->'UK004D00040' FROM cityCodeMap\")\n",
    "print(cur.fetchone()[0])\n",
    "\n",
    "# Can we persist the dict as JSON in  database?\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works, but doesn't seem very handy... another alternative is to load the whole CSV simply into a Table in the Database... let's write some simple code that takes a CSV file and \n",
    "* generates a table from the first row (header)\n",
    "* inserts all the remaining data.\n",
    "That's also probably very naive..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "cityCodeFile=\"./data/cities.csv\"\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=postgres user=postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# We create a table from the first 7 columns of the file: \n",
    "with open(cityCodeFile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "\n",
    "    header = \"CREATE TABLE cityCodeFile_raw (\"+ ', '.join([col.replace('\"', '') + \" varchar \" for col in (next(csvfile))[:7]]) + \");\"\n",
    "\n",
    "    #cur.execute(header)\n",
    "\n",
    "    for row in csvfile:\n",
    "        cur.execute(\"INSERT INTO cityCodeFile_raw VALUES (\"+ ','.join([\"'\" + str(i).replace(\"'\", '\"') + \"'\" for i in row[:7]]) + \")\")\n",
    "        \n",
    "\n",
    "# Can we persist the dict as JSON in  database?\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't solved this example until the end for you: To solve the overall task, you could now proceed similarly with the other tables, load them (or respectively, the relevant columns) into the database and  then work with SQL queries and joins, to get the right information out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
