{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate detection\n",
    "\n",
    "**Question:** What is the (most recent) population number of London?\n",
    "\n",
    "Two datasets: \n",
    "* [UrbanAudit](./data/urb_cpop1.csv) - indicator DE1001V is the total population, names of cities are in a separate file [cities.csv](./data/cities.csv)\n",
    "* [UNData](./data/UNdata_Export_20161031_132143657.csv) - total population is indicated by the values \n",
    "\n",
    "    \"Total\",\"Both Sexes\"\n",
    "    \n",
    "  in the 3rd and 4th column, city name is in the 5th column, some city names are in upper case. The source year is in the 9th column and the actual population number is in the 10th column.\n",
    "  \n",
    "Let's try to get the data into a unique format into **one** dictionary. For the EU data we have done this last time already, let's take  the same code and slightly adapt it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': '2013 ', 'pop': 1741246}\n"
     ]
    }
   ],
   "source": [
    "import csv # for handling csv/tsv files\n",
    "\n",
    "urbanAuditFile=\"./data/urb_cpop1.tsv\"\n",
    "cityCodeFile=\"./data/cities.csv\"\n",
    "\n",
    "#Building the cityCode to Label map\n",
    "cityCodeMap={}\n",
    "with open(cityCodeFile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "    for i,row in enumerate(csvfile):\n",
    "        cityCodeMap[row[3]]= row[1]\n",
    "#cityCodeMap\n",
    "\n",
    "recentCityPopulationEU={} # key= cityname-lowercase-ISO-20letter-country code, \n",
    "                          # value = {'year': year, 'pop':population}\n",
    "\n",
    "## a quick trick to be able to convert the yearIndex to its label\n",
    "## We know this snippet from last time... now we will use the lower-case for the labels, in order \n",
    "## to avoid confusion with upper and lower case names:\n",
    "\n",
    "headerRow=[]\n",
    "with open(urbanAuditFile) as f:\n",
    "    csvfile = csv.reader(f, delimiter=\"\\t\")\n",
    "    for i, row in enumerate(csvfile):\n",
    "        if i==0:\n",
    "            headerRow=row\n",
    "        if 'DE1001V' in row[0] and len(row[0])> len(\"DE1001V,AT\"): # same filter conditition as before\n",
    "            for yearIndex in range (1,27): # this generates all numbers between 1 and 27\n",
    "                popCount=row[yearIndex].strip().split(\" \")[0]\n",
    "                if popCount != \":\" and int(popCount)>0: # check if value exists and we can convert it\n",
    "                    #ok we have a population value >0, that is hte most recent year, lets store this\n",
    "                    cityPopulation=int(popCount)\n",
    "                    cityCode=row[0].split(\",\")[1]\n",
    "                    cityLabel=cityCodeMap[cityCode].lower() # lets just merge the mapping from city code to label in this code\n",
    "                    # small modification, we also add the 2 letter country code in uppercase to the key (we will need this later:\n",
    "                    cityLabelCC = cityLabel + (row[0].split(',')[1][0:2])  \n",
    "                    recentCityPopulationEU[cityLabelCC]={'year': headerRow[yearIndex],'pop': cityPopulation, } # we also convert the year index to the year label\n",
    "                    break\n",
    "                    \n",
    "## Again, we could print this: \n",
    "# print(\"Number of cities: \"+str(len(recentCityPopulationEU.keys())))\n",
    "# for city, pop in recentCityPopulationEU.items():\n",
    "#    print(\"  \"+city+\":\"+str(pop['pop'])+\" in \"+str(pop['year']))\n",
    "\n",
    "# Example:\n",
    "print(recentCityPopulationEU['wienAT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now let's look into the UN Data file and while we build up a similar dictionary, try to cautiously check for duplicates. To this end, for the moment, we also store the original rows in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undatafile = 'data/UNdata_Export_20161031_132143657.csv'\n",
    "\n",
    "recentCityPopulationUN={}\n",
    "\n",
    "with open(undatafile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "\n",
    "    for row in csvfile:\n",
    "        if len(row) > 10 and row[2] == \"Total\" and row[3] == \"Both Sexes\":\n",
    "            cityLabel = row[4].lower()\n",
    "            # The if part covers dedectung duplicates:\n",
    "            if cityLabel in recentCityPopulationUN and recentCityPopulationUN[cityLabel]['year'] <= row[8]:\n",
    "                if recentCityPopulationUN[cityLabel]['year'] == row[8]:\n",
    "                    print(\"Duplicate found!\\n\" + str(row) + \"\\n\" + str(recentCityPopulationUN[cityLabel]['row']) + \"\\n\")\n",
    "                # implicit missing 'else' branch: if the year was older than the one already sotred, then ignore this line.\n",
    "            else:\n",
    "                recentCityPopulationUN[cityLabel] = {'year': row[8],'pop': float(row[9]), 'row' : row} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! This produces a lot of duplicates, e.g.:\n",
    "    \n",
    "    Duplicate found!\n",
    "    ['Åland Islands', '2008', 'Total', 'Both Sexes', 'MARIEHAMN', 'City proper', 'Estimate - de jure', 'Final figure, complete', '2009', '10954', '1']\n",
    "    ['Åland Islands', '2009', 'Total', 'Both Sexes', 'MARIEHAMN', 'City proper', 'Estimate - de jure', 'Final figure, complete', '2009', '11064', '1']\n",
    "    \n",
    "What this tells us it that different *reported* years (2nd column) in the data seem to have the same source year (9th column).We can eliminate these duplicates easily by just referring to the reported year instead of the source year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recentCityPopulationUN={}\n",
    "\n",
    "with open(undatafile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "\n",
    "    for row in csvfile:\n",
    "        if len(row) > 10 and row[2] == \"Total\" and row[3] == \"Both Sexes\":\n",
    "            cityLabel = row[4].lower()\n",
    "            # Note that we changed to row[1] here:\n",
    "            if cityLabel in recentCityPopulationUN and recentCityPopulationUN[cityLabel]['year'] <= row[1]:\n",
    "                if recentCityPopulationUN[cityLabel]['year'] == row[1]:\n",
    "                    print(\"Duplicate found!\\n\" + str(row) + \"\\n\" + str(recentCityPopulationUN[cityLabel]['row']) + \"\\n\"  )\n",
    "            else:\n",
    "                recentCityPopulationUN[cityLabel] = {'year': row[1],'pop': float(row[9]),'row' : row} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouch! Again there are many duplicates in the data... E.g.:\n",
    "    \n",
    "    Duplicate found!\n",
    "    ['Argentina', '1991', 'Total', 'Both Sexes', 'BUENOS AIRES', 'Urban agglomeration', 'Census - de facto - complete tabulation', 'Final figure, complete', '1991', '11298030', '']\n",
    "    ['Argentina', '1991', 'Total', 'Both Sexes', 'BUENOS AIRES', 'City proper', 'Census - de facto - complete tabulation', 'Final figure, complete', '1991', '2965403', '']\n",
    "\n",
    "These seem to indicate that the UN Dataset have also the same city name appearing in different city types: the \"Urban agglomeration\" area or the \"City proper\" area.\n",
    "Let's fix the code to prefer the numbers given for the \"Urban agglomeration\", in such cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recentCityPopulationUN={}\n",
    "\n",
    "with open(undatafile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "\n",
    "    for row in csvfile:\n",
    "        if len(row) > 10 and row[2] == \"Total\" and row[3] == \"Both Sexes\":\n",
    "            cityLabel = row[4].lower()\n",
    "            if (cityLabel in recentCityPopulationUN and recentCityPopulationUN[cityLabel]['year'] <= row[1] and \n",
    "                # Adding another condition: only report a duplicate when the new city type is not \"City Proper\" and the to be replaced type is not \"Urban agglomeration\" \n",
    "                not (row[5] == \"Urban agglomeration\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5] == \"City proper\")):\n",
    "                if recentCityPopulationUN[cityLabel]['year'] == row[1]:\n",
    "                    print(\"Duplicate found!\\n\" + str(row) + \"\\n\" + str(recentCityPopulationUN[cityLabel]['row']) + \"\\n\"  )\n",
    "            else:\n",
    "                recentCityPopulationUN[cityLabel] = {'year': row[1],'pop': float(row[9]),'row' : row} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, again duplicates, this time of the form:\n",
    "    \n",
    "    Duplicate found!\n",
    "    ['Austria', '2011', 'Total', 'Both Sexes', 'Bregenz', 'City proper', 'Estimate - de jure', 'Final figure, complete', '2011', '27784', '18']\n",
    "    ['Austria', '2011', 'Total', 'Both Sexes', 'Bregenz', 'City proper', 'Census - de jure - complete tabulation', 'Final figure, complete', '2012', '27831', '']\n",
    "    \n",
    "Now these indicate that there are different measure methods... here we could opt to overwrite estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recentCityPopulationUN={}\n",
    "\n",
    "with open(undatafile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "\n",
    "    for row in csvfile:\n",
    "        if len(row) > 10 and row[2] == \"Total\" and row[3] == \"Both Sexes\":\n",
    "            cityLabel = row[4].lower()\n",
    "            if (cityLabel in recentCityPopulationUN and recentCityPopulationUN[cityLabel]['year'] <= row[1] and \n",
    "                # Adding another condition: only report a duplicate when the existing city type is not \"City Proper\" and the to be replaced type is not \"Urban agglomeration\" \n",
    "                not (row[5] == \"Urban agglomeration\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5] == \"City proper\") and\n",
    "                # Adding another condition: only report a duplicate when the existing method not is \"Estimate ...\" and new one is something else. \n",
    "                not (row[6][0:7] != \"Estimate\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5][0:7] == \"Estimate\")):\n",
    "                if (recentCityPopulationUN[cityLabel]['year'] == row[1] and\n",
    "                    row[6][0:7] != \"Estimate\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5][0:7] == \"Estimate\"):\n",
    "                    print(\"Duplicate found!\\n\" + str(row) + \"\\n\" + str(recentCityPopulationUN[cityLabel]['row']) + \"\\n\"  )\n",
    "\n",
    "            else:\n",
    "                recentCityPopulationUN[cityLabel] = {'year': row[1],'pop': float(row[9]),'row' : row}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more duplicates found, although, that was quite ugly!\n",
    "\n",
    "We could have chosen another resolution strategy, e.g.\n",
    "\n",
    "* collect all available values for the most recent year and take the average\n",
    "* collect all available values for the most recent year and take the maximum\n",
    "\n",
    "... each of those has pros and cons, depending on the use case. \n",
    "\n",
    "Let's try one of these strategies with the **merged** UN and EU datasets! But wait a second...\n",
    "\n",
    "## Did we really resolve all duplicates now?\n",
    "\n",
    "Have we really resolved all duplicates now?\n",
    "\n",
    "What about cities with the same names in different countries? Let's check whether such cases exist in the UN dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(undatafile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "    \n",
    "    city_country_dict = {}\n",
    "\n",
    "    # we want to build up a dictionary to check whether there are cities with the same \n",
    "    # name but different countries in our dataset\n",
    "    # i.e. key = cityname value = country \n",
    "\n",
    "    for row in csvfile:\n",
    "        if len(row) > 10 and row[2] == \"Total\" and row[3] == \"Both Sexes\":\n",
    "            cityLabel = row[4].lower()\n",
    "            country = row[0].lower()\n",
    "            if  (cityLabel in city_country_dict and\n",
    "                 city_country_dict[cityLabel] != country):\n",
    "                print(\"Different countries found for City: '\" + cityLabel + \"': \" + country + \" and \" + city_country_dict[cityLabel]) \n",
    "            else:\n",
    "                city_country_dict[cityLabel] = country \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too bad, e.g.: \n",
    "    \n",
    "    Different countries found for City: london: united kingdom of great britain and northern ireland and canada\n",
    "    \n",
    "we can fix this by adding the country code to the city label, remember, we did that before for the Eurostat cities, but here it is more difficult, since we need to lookup the country codes in the ISO file (to arrive at the same lables we had in the EU file!\n",
    "\n",
    "Let's first build a dictionary of countrycodes... We have seen that last time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countryCodeFile = './data/iso_3166_2_countries.csv'\n",
    "\n",
    "countryCodeDict = {}\n",
    "\n",
    "with open(countryCodeFile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "    for row in csvfile:\n",
    "        countryCodeDict[row[1]] = row[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use this dictionary to modify the example code from above to rebuild the UN city population dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Åland Islands'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-54216ef13180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# This is the only modification: we add a lookup for the countryname to append the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# countrycode to the city label:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mcityLabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcountryCodeDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             if (cityLabel in recentCityPopulationUN and recentCityPopulationUN[cityLabel]['year'] <= row[1] and \n\u001b[1;32m     12\u001b[0m                 not (row[5] == \"Urban agglomeration\" and  \n",
      "\u001b[0;31mKeyError\u001b[0m: 'Åland Islands'"
     ]
    }
   ],
   "source": [
    "recentCityPopulationUN={}\n",
    "\n",
    "with open(undatafile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "\n",
    "    for row in csvfile:\n",
    "        if len(row) > 10 and row[2] == \"Total\" and row[3] == \"Both Sexes\":\n",
    "            # This is the only modification: we add a lookup for the countryname to append the \n",
    "            # countrycode to the city label: \n",
    "            cityLabel = row[4].lower() + countryCodeDict[row[0]] \n",
    "            if (cityLabel in recentCityPopulationUN and recentCityPopulationUN[cityLabel]['year'] <= row[1] and \n",
    "                not (row[5] == \"Urban agglomeration\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5] == \"City proper\") and\n",
    "                not (row[6][0:7] != \"Estimate\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5][0:7] == \"Estimate\")):\n",
    "                if (recentCityPopulationUN[cityLabel]['year'] == row[1] and\n",
    "                    row[6][0:7] != \"Estimate\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5][0:7] == \"Estimate\"):\n",
    "                    print(\"Duplicate found!\\n\" + str(row) + \"\\n\" + str(recentCityPopulationUN[cityLabel]['row']) + \"\\n\"  )\n",
    "            else:\n",
    "                recentCityPopulationUN[cityLabel] = {'year': row[1],'pop': float(row[9]),'row' : row}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too bad, that doesn't work, since some countries have different names in the countries file from ISO and from the UN.\n",
    "We would probably need additional data to resolve these... for the moment, we will simply ignore those countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recentCityPopulationUN={}\n",
    "\n",
    "with open(undatafile) as f:\n",
    "    csvfile = csv.reader(f)\n",
    "\n",
    "    for row in csvfile:\n",
    "        if len(row) > 10 and row[2] == \"Total\" and row[3] == \"Both Sexes\":\n",
    "            if row[0] in countryCodeDict:\n",
    "                cityLabel = row[4].lower() + countryCodeDict[row[0]]\n",
    "                # print(cityLabel)\n",
    "            else: continue # continue jumps over this row and continues in the next iteration of the for loop \n",
    "            if (cityLabel in recentCityPopulationUN and recentCityPopulationUN[cityLabel]['year'] <= row[1] and \n",
    "                # Adding another condition: only report a duplicate when the existing city type is not \"City Proper\" and the to be replaced type is not \"Urban agglomeration\" \n",
    "                not (row[5] == \"Urban agglomeration\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5] == \"City proper\") and\n",
    "                # Adding another condition: only report a duplicate when the existing method not is \"Estimate ...\" and new one is something else. \n",
    "                not (row[6][0:7] != \"Estimate\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5][0:7] == \"Estimate\")):\n",
    "                if (recentCityPopulationUN[cityLabel]['year'] == row[1] and\n",
    "                    row[6][0:7] != \"Estimate\" and  \n",
    "                     recentCityPopulationUN[cityLabel]['row'][5][0:7] == \"Estimate\"):\n",
    "                    print(\"Duplicate found!\\n\" + str(row) + \"\\n\" + str(recentCityPopulationUN[cityLabel]['row']) + \"\\n\"  )\n",
    "            else:\n",
    "                recentCityPopulationUN[cityLabel] = {'year': row[1],'pop': float(row[9]),'row' : row}             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be ready to merge the two datasets! our strategy is to build a joint dictionary `recentCityPopulation`, \n",
    "where we collect the average pop `popAvg` `popEU` and `popUN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'popUN': 1829876.0, 'pop': 1785561.0, 'popEU': 1741246}\n"
     ]
    }
   ],
   "source": [
    "recentCityPopulation = {}\n",
    "\n",
    "for key in recentCityPopulationUN:\n",
    "    recentCityPopulation[key] = {'popUN': recentCityPopulationUN[key]['pop'],\n",
    "                                 'pop' : recentCityPopulationUN[key]['pop'] }\n",
    "\n",
    "\n",
    "for key in recentCityPopulationEU:\n",
    "    if key in recentCityPopulation:\n",
    "        recentCityPopulation[key]['popEU'] = recentCityPopulationEU[key]['pop'] \n",
    "        recentCityPopulation[key]['pop'] = (recentCityPopulation[key]['pop'] + recentCityPopulation[key]['popEU'])/2 \n",
    "    else: \n",
    "        recentCityPopulation[key] = {'popEU': recentCityPopulationEU[key]['pop'],\n",
    "                                     'pop' : recentCityPopulationEU[key]['pop'] }\n",
    "# An example:        \n",
    "print(recentCityPopulation['wienAT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework: \n",
    "\n",
    "How could we resolve the issues with different city and country names in the EU and UN dataset (e.g. \"Åland Islands\" vs. \"Aland\", or \"Wien\" vs. \"Vienna\", or \"Helsinki\" vs. \"Helsinki / Helsingfors\"). Think about strategies or additional datasets you could use! More on that in the last lecture or in the SBWL course 3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
